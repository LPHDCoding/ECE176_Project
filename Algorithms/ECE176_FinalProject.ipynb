{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 176: Fine-Grained Classification Using a CB-ViT Model\n",
    "\n",
    "The focus of our final project will be reimplmenenting the work of Shuo Zhu, Xukang Zhang, Yu Wang, Zhongyang Wang, and Jiahao Sun. The main result of this paper is the introduction of a CB-ViT model. This model combines the local feature extraction of Convolutional networks with the broad feature extraction of Vision Transformers. A version of their reseach paper can be found here: https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/ipr2.13295. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports - reused from assignment 5\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F  # useful stateless functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data setup - reused from assignment 5\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "batch_size= 64\n",
    "\n",
    "# The torchvision.transforms package provides tools for preprocessing data\n",
    "# and for performing data augmentation; here we set up a transform to\n",
    "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
    "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
    "\n",
    "#===========================================================================#\n",
    "# You should try changing the transform for the training data to include    #\n",
    "# data augmentation such as RandomCrop and HorizontalFlip                    #\n",
    "# when running the final part of the notebook where you have to achieve     #\n",
    "# as high accuracy as possible on CIFAR-100.                                #\n",
    "# Of course you will have to re-run this block for the effect to take place #\n",
    "#===========================================================================#\n",
    "train_transform = transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "            ])\n",
    "\n",
    "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
    "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
    "# iterates through the Dataset and forms minibatches. We divide the CIFAR-100\n",
    "# training set into train and val sets by passing a Sampler object to the\n",
    "# DataLoader telling how it should sample from the underlying Dataset.\n",
    "cifar100_train = dset.CIFAR100('./datasets/cifar100', train=True, download=True,\n",
    "                             transform=train_transform)\n",
    "loader_train = DataLoader(cifar100_train, batch_size=batch_size, num_workers=2,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar100_val = dset.CIFAR100('./datasets/cifar100', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar100_val, batch_size=batch_size, num_workers=2, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar100_test = dset.CIFAR100('./datasets/cifar100', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar100_test, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Dtype and device selection - reused from assignment 5\n",
    "\n",
    "USE_GPU = True\n",
    "num_class = 100\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten function - reused from assignment 5\n",
    "\n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "# We need to wrap `flatten` function in a module in order to stack it\n",
    "# in nn.Sequential\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0920,  0.7641,  1.6868, -1.1250, -0.9672],\n",
       "        [ 0.3663,  0.3248, -1.2695, -0.1080, -1.2500],\n",
       "        [-0.2060, -0.5298,  1.4241, -0.6449, -0.4094]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random weight function - reused from assignment 5\n",
    "\n",
    "def random_weight(shape):\n",
    "    \"\"\"\n",
    "    Create random Tensors for weights; setting requires_grad=True means that we\n",
    "    want to compute gradients for these Tensors during the backward pass.\n",
    "    We use Kaiming normalization: sqrt(2 / fan_in)\n",
    "    \"\"\"\n",
    "    if len(shape) == 2:  # FC weight\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n",
    "    # randn is standard normal distribution generator. \n",
    "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
    "    w.requires_grad = True\n",
    "    return w\n",
    "\n",
    "def zero_weight(shape):\n",
    "    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "# create a weight of shape [3 x 5]\n",
    "# you should see the type `torch.cuda.FloatTensor` if you use GPU. \n",
    "# Otherwise it should be `torch.FloatTensor`\n",
    "random_weight((3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy function - reused from assignment 5\n",
    "\n",
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function - reused from assignment 5\n",
    "\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: The accuracy of the model\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if (t + 1) % print_every == 0:\n",
    "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, t + 1, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()\n",
    "    return check_accuracy_part34(loader_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample class - reused from assignment 5\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channel, channel_1, (5,5), padding=2)\n",
    "        nn.init.kaiming_normal_(self.conv_1.weight)\n",
    "        self.conv_2 = nn.Conv2d(channel_1, channel_2, (3,3), padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv_2.weight)\n",
    "        self.fc1 = nn.Linear(65536, num_classes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        scores = self.fc1(flatten(F.relu(self.conv_2(F.relu(self.conv_1(x))))))\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 100, loss = 4.0000\n",
      "Checking accuracy on validation set\n",
      "Got 65 / 1000 correct (6.50)\n",
      "\n",
      "Epoch 0, Iteration 200, loss = 3.8828\n",
      "Checking accuracy on validation set\n",
      "Got 111 / 1000 correct (11.10)\n",
      "\n",
      "Epoch 0, Iteration 300, loss = 3.7398\n",
      "Checking accuracy on validation set\n",
      "Got 119 / 1000 correct (11.90)\n",
      "\n",
      "Epoch 0, Iteration 400, loss = 3.8292\n",
      "Checking accuracy on validation set\n",
      "Got 146 / 1000 correct (14.60)\n",
      "\n",
      "Epoch 0, Iteration 500, loss = 3.6670\n",
      "Checking accuracy on validation set\n",
      "Got 143 / 1000 correct (14.30)\n",
      "\n",
      "Epoch 0, Iteration 600, loss = 3.8485\n",
      "Checking accuracy on validation set\n",
      "Got 164 / 1000 correct (16.40)\n",
      "\n",
      "Epoch 0, Iteration 700, loss = 3.5879\n",
      "Checking accuracy on validation set\n",
      "Got 183 / 1000 correct (18.30)\n",
      "\n",
      "Checking accuracy on validation set\n",
      "Got 160 / 1000 correct (16.00)\n"
     ]
    }
   ],
   "source": [
    "# Training and validating of sample class - reused from assignment 5\n",
    "\n",
    "learning_rate = 1e-3\n",
    "channel_1 = 32\n",
    "channel_2 = 64\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "model = Network(3, channel_1, channel_2, 100)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print_every = 100\n",
    "train_part34(model, optimizer, epochs=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 50\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels, filters, kernel_size):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        F1, F2, F3 = filters\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, F1, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(F1, F2, kernel_size=kernel_size, stride=1,\n",
    "                               padding=kernel_size // 2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(F2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(F2, F3, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(F3)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        out += shortcut\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ConvolutionalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, filters, kernel_size, stride):\n",
    "        super(ConvolutionalBlock, self).__init__()\n",
    "        F1, F2, F3 = filters\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, F1, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(F1, F2, kernel_size=kernel_size, stride=1,\n",
    "                               padding=kernel_size // 2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(F2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(F2, F3, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(F3)\n",
    "        \n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, F3, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(F3)\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        out += shortcut\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(ResNet50, self).__init__()\n",
    "        # Initial convolution and max-pooling\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Stage 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ConvolutionalBlock(64, filters=(64, 64, 256), kernel_size=3, stride=1),\n",
    "            IdentityBlock(256, filters=(64, 64, 256), kernel_size=3),\n",
    "            IdentityBlock(256, filters=(64, 64, 256), kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        # Stage 3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            ConvolutionalBlock(256, filters=(128, 128, 512), kernel_size=3, stride=2),\n",
    "            IdentityBlock(512, filters=(128, 128, 512), kernel_size=3),\n",
    "            IdentityBlock(512, filters=(128, 128, 512), kernel_size=3),\n",
    "            IdentityBlock(512, filters=(128, 128, 512), kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        # Stage 4\n",
    "        self.layer4 = nn.Sequential(\n",
    "            ConvolutionalBlock(512, filters=(256, 256, 1024), kernel_size=3, stride=2),\n",
    "            IdentityBlock(1024, filters=(256, 256, 1024), kernel_size=3),\n",
    "            IdentityBlock(1024, filters=(256, 256, 1024), kernel_size=3),\n",
    "            IdentityBlock(1024, filters=(256, 256, 1024), kernel_size=3),\n",
    "            IdentityBlock(1024, filters=(256, 256, 1024), kernel_size=3),\n",
    "            IdentityBlock(1024, filters=(256, 256, 1024), kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        # Stage 5\n",
    "        self.layer5 = nn.Sequential(\n",
    "            ConvolutionalBlock(1024, filters=(512, 512, 2048), kernel_size=3, stride=2),\n",
    "            IdentityBlock(2048, filters=(512, 512, 2048), kernel_size=3),\n",
    "            IdentityBlock(2048, filters=(512, 512, 2048), kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        # Average pooling and fully connected layer\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 3, H, W)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"CNN Modules\"\n",
    "\n",
    "class FEM(nn.Module):\n",
    "    def __init__(self, in_channel, in_height, in_width):\n",
    "        super().__init__()\n",
    "        self.conv3_1 = nn.Conv2d(in_channel, in_channel, (3,3), padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv3_1.weight)\n",
    "        self.batch31 = nn.BatchNorm2d(in_channel)\n",
    "        self.silu31 = nn.SiLU()\n",
    "        self.conv5 = nn.Conv2d(in_channel, in_channel, (5,5), padding=2)\n",
    "        nn.init.kaiming_normal_(self.conv5.weight)\n",
    "        self.batch5 = nn.BatchNorm2d(in_channel)\n",
    "        self.silu5 = nn.SiLU()\n",
    "        self.max = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.avg = nn.AvgPool2d(kernel_size=(2,2))\n",
    "        self.conv3_2 = nn.Conv2d(in_channel, in_channel, (3,3), padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv3_2.weight)\n",
    "        self.flatten = Flatten()\n",
    "        fc_size = int(in_channel*(2*np.floor(in_height/2))*(np.floor(in_width/2)))\n",
    "        self.fc = nn.Linear(fc_size, in_width)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        R1 = self.silu31(self.batch31(self.conv3_1(x)))\n",
    "        R2 = self.silu5(self.batch5(self.conv5(x)))\n",
    "        Rm = R1 + R2\n",
    "        Rn = torch.cat((self.max(Rm), self.avg(Rm)), dim=2)\n",
    "        Rp = self.conv3_2(Rn)\n",
    "        M = self.fc(self.flatten(Rp))\n",
    "        gamma = self.soft(M)\n",
    "        Rx = torch.mul(R1, gamma) + torch.mul(R2, 1-gamma)\n",
    "        return Rx\n",
    "    \n",
    "class CNN_Block(nn.Module):\n",
    "    def __init__(self, in_channel, hidden_channel, in_height, in_width):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, hidden_channel, (1,1), padding=0)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        self.batch1 = nn.BatchNorm2d(hidden_channel)\n",
    "        self.silu1 = nn.SiLU()\n",
    "        self.conv3 = nn.Conv2d(hidden_channel, hidden_channel, (3,3), padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv3.weight)\n",
    "        self.batch3 = nn.BatchNorm2d(hidden_channel)\n",
    "        self.silu3 = nn.SiLU()\n",
    "        self.FEM = FEM(hidden_channel, in_height, in_width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.FEM(self.silu3(self.batch3(self.conv3(self.silu1(self.batch1(self.conv1(x)))))))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SFE \n",
    "\n",
    "class SFE(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super().__init__()\n",
    "        self.conv3_1 = nn.Conv2d(in_channel, in_channel, (3,3), stride=2, padding=2)\n",
    "        nn.init.kaiming_normal_(self.conv3_1.weight)\n",
    "        self.batch3_1 = nn.BatchNorm2d(in_channel)\n",
    "        self.relu3_1 = nn.ReLU()\n",
    "        self.conv3_2 = nn.Conv2d(in_channel, in_channel, (3,3), stride=2, padding=2)\n",
    "        nn.init.kaiming_normal_(self.conv3_2.weight)\n",
    "        self.batch3_2 = nn.BatchNorm2d(in_channel)\n",
    "        self.relu3_2 = nn.ReLU()\n",
    "        self.conv3_3 = nn.Conv2d(in_channel, in_channel, (3,3), stride=2, padding=2)\n",
    "        nn.init.kaiming_normal_(self.conv3_3.weight)\n",
    "        self.batch3_3 = nn.BatchNorm2d(in_channel)\n",
    "        self.relu3_3 = nn.ReLU()\n",
    "        self.conv3_4 = nn.Conv2d(in_channel, in_channel, (3,3), stride=2, padding=2)\n",
    "        nn.init.kaiming_normal_(self.conv3_4.weight)\n",
    "        self.batch3_4 = nn.BatchNorm2d(in_channel)\n",
    "        self.relu3_4 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channel, in_channel, (1,1), stride=1, padding=2)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        self.batch1 = nn.BatchNorm2d(in_channel)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.relu1(self.batch1(self.conv1(self.relu3_4(self.batch3_4(self.conv3_4(self.relu3_3(self.batch3_3(self.conv3_3(self.relu3_2(self.batch3_2(self.conv3_2(self.relu3_1(self.batch3_1(self.conv3_1(x)))))))))))))))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Test FEM\n",
    "x = torch.ones((1,3,128,128), dtype=dtype) # NxCxHxW\n",
    "model = FEM(3, 128, 128)\n",
    "output = model(x)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 255, 123])\n"
     ]
    }
   ],
   "source": [
    "# Test CNN_Block\n",
    "x = torch.ones((1,32,255,123), dtype=dtype) # NxCxHxW\n",
    "model = CNN_Block(32, 3, 255, 123)\n",
    "output = model(x)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "# Test SFE\n",
    "x = torch.ones((1,3,128,128), dtype=dtype) # NxCxHxW\n",
    "model = SFE(3)\n",
    "output = model(x)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m     10\u001b[0m print_every \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m700\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrain_part34\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m print_every \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mtrain_part34\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_part34\u001b[39m(model, optimizer, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    Train a model on CIFAR-10 using the PyTorch Module API.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Returns: The accuracy of the model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# move the model parameters to CPU/GPU\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader_train):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((1, 3, 64, 64), dtype=dtype)\n",
    "model = ResNet50()\n",
    "output = model(x)\n",
    "print(output.size())\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print_every = 700\n",
    "train_part34(model, optimizer, epochs=10)\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
